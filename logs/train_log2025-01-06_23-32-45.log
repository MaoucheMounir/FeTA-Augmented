Data Augmentation:['color_jitter']
{'data_path': '/home/imag2/Desktop/BabySynthSeg-main/Data/FeTA_2022_test/mri', 'labels_path': '/home/imag2/Desktop/BabySynthSeg-main/Data/FeTA_2022_test/segmentation', 'weights_path': '/home/imag2/Desktop/Segmentation-Mounir/BabySynthSeg copie/weights_mounir', 'input_ch': 1, 'output_ch': 2, 'nb_dataloaders': 1, 'patch_size': (96, 96, 96), 'stride': 32, 'lr': 0.01, 'test_split': 0.2, 'val_split': 0.1, 'smooth': 1e-05, 'ee': 2.220446049250313e-16, 'num_epochs': 100, 'batch_size': 2, 'device': 'cuda', 'note': 'Enleve autocast, ajoute color_jitter'}  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/imag2/Desktop/Segmentation-Mounir/BabySynthSeg copie/3D_U-Net/a3D_UNet_1dataloader_1label.py", line 325, in <module>
    x = apply_data_augmentation(*data_augmentations)(x)
  File "/home/imag2/miniconda3/envs/UnetGarance/lib/python3.9/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/imag2/miniconda3/envs/UnetGarance/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/imag2/miniconda3/envs/UnetGarance/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/imag2/miniconda3/envs/UnetGarance/lib/python3.9/site-packages/torchvision/transforms/v2/_transform.py", line 50, in forward
    flat_outputs = [
  File "/home/imag2/miniconda3/envs/UnetGarance/lib/python3.9/site-packages/torchvision/transforms/v2/_transform.py", line 51, in <listcomp>
    self._transform(inpt, params) if needs_transform else inpt
  File "/home/imag2/miniconda3/envs/UnetGarance/lib/python3.9/site-packages/torchvision/transforms/v2/_color.py", line 167, in _transform
    output = self._call_kernel(F.adjust_saturation, output, saturation_factor=saturation_factor)
  File "/home/imag2/miniconda3/envs/UnetGarance/lib/python3.9/site-packages/torchvision/transforms/v2/_transform.py", line 35, in _call_kernel
    return kernel(inpt, *args, **kwargs)
  File "/home/imag2/miniconda3/envs/UnetGarance/lib/python3.9/site-packages/torchvision/transforms/v2/functional/_color.py", line 159, in adjust_saturation_image
    raise TypeError(f"Input image tensor permitted channel values are 1 or 3, but found {c}")
TypeError: Input image tensor permitted channel values are 1 or 3, but found 96
